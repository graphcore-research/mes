{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "import os\n",
    "\n",
    "# Add directory where 'latex' is installed\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/Library/TeX/texbin\"\n",
    "\n",
    "plt.style.use(['science', 'grid', 'retro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path().cwd()\n",
    "\n",
    "RESULTS_DIR = ROOT / \"results\" # mes/paper_experiments/results\n",
    "SAVE_DIR = ROOT / \"plots\" # mes/paper_experiments/paper_plots\n",
    "\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert RESULTS_DIR.exists(), f\"{RESULTS_DIR} does not exist\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20458817",
   "metadata": {},
   "source": [
    "# Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_concat_json_files(*, results_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all the individual JSON files from each run and concatenate them into a \n",
    "    single dataframe.\n",
    "\n",
    "    Args:\n",
    "        results_dir: The absolute path to the directory containing the JSON files\n",
    "\n",
    "    Returns:\n",
    "        df_master: A dataframe with the results of all the runs\n",
    "    \"\"\"\n",
    "    # I was an idiot and forgot to include the acq fun in the BO runs,\n",
    "    # so we have to parse it from the filename for now. This has since\n",
    "    # been fixed, but we keep this for now for backwards compatibility.\n",
    "    acq_funs = [\n",
    "        \"expected_improvement\",\n",
    "        \"random_search\",\n",
    "        \"ves_gamma_0_0\",\n",
    "        \"ves_gamma_0_1\",\n",
    "        \"ves_gamma_0_2\",\n",
    "        \"ves_mc_gamma\",\n",
    "        \"ves_exp_0\",\n",
    "        \"ves_exp_1\",\n",
    "        \"ves_exp_2\",\n",
    "        \"ves_mc_exponential\",\n",
    "        \"ves_lr_0_0\",\n",
    "        \"ves_lr_0_1\",\n",
    "        \"ves_lr_0_2\",\n",
    "        \"ves_lr_2_0\",\n",
    "        \"ves_lr_2_1\",\n",
    "        \"ves_lr_2_2\",\n",
    "        \"ves_mc_gaussian\",\n",
    "    ]\n",
    "    def parse_af_from_name(filename:str) -> str:\n",
    "        return [af for af in acq_funs if af in filename][0]\n",
    "\n",
    "\n",
    "    res_files = list(results_dir.glob(\"*.json\"))\n",
    "    print(f\"Found {len(res_files)} files in {results_dir}\")\n",
    "\n",
    "    df_list = []\n",
    "    for file in res_files:\n",
    "        df_i = pd.read_json(file)\n",
    "        df_i[\"acq_func\"] = parse_af_from_name(str(file))\n",
    "        df_list.append(df_i)\n",
    "    df_master = pd.concat(df_list)\n",
    "\n",
    "    print(f\"Parsed {len(res_files)} files with {len(df_master)} rows\")\n",
    "    return df_master\n",
    "\n",
    "\n",
    "def load_results_cached(*, results_subfolder: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the results from the given subfolder. If a cached version of the results\n",
    "    exists, load it from there. Otherwise, load the results from the subfolder and\n",
    "    save the results to the cache.\n",
    "\n",
    "    Args:\n",
    "        results_subfolder: The subfolder containing the results, e.g. \"0\"\n",
    "\n",
    "    Returns:\n",
    "        A dataframe with the results of all the runs\n",
    "    \"\"\"\n",
    "    df_master_filename = RESULTS_DIR / f\"{results_subfolder}_results_data.csv.gz\"\n",
    "\n",
    "    if not df_master_filename.exists():\n",
    "        df_master = load_and_concat_json_files(results_dir=RESULTS_DIR / results_subfolder)\n",
    "        df_master.to_csv(df_master_filename, index=False, compression=\"gzip\")\n",
    "        print(f\"Saved {len(df_master)} rows to {df_master_filename}\")\n",
    "    else:\n",
    "        df_master = pd.read_csv(df_master_filename)\n",
    "        print(f\"Loaded {len(df_master)} rows from {df_master_filename}\")\n",
    "\n",
    "    return df_master\n",
    "\n",
    "\n",
    "# folder \"0\" has all runs used in the paper results section\n",
    "results_subfolder = \"0\"\n",
    "df_master = load_results_cached(results_subfolder=results_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68507546",
   "metadata": {},
   "source": [
    "## Computing Mean, STD for each kernel/AF/dim/ynoise/lenscale\n",
    "\n",
    "And a single plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5389dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result_columns(Enum):\n",
    "    y_max_diff = \"y_max_diff\"\n",
    "    y_rec_diff_max = \"y_rec_diff_max\"\n",
    "    y_max_var = \"y_max_var\"\n",
    "    y_rec_var = \"y_rec_var\"\n",
    "\n",
    "\n",
    "# nice user friendly names for the acquisition functions to use\n",
    "# in plot legend.\n",
    "ALG_NAMES = {\n",
    "    \"expected_improvement\": \"EI\",\n",
    "    \"random_search\": \"RS\",\n",
    "    \"ves_gamma_0_0\": r\"$\\Gamma$ Constant\",\n",
    "    \"ves_gamma_0_1\": r\"$\\Gamma$ Linear\",\n",
    "    \"ves_gamma_0_2\": r\"$\\Gamma$ ReLu\",\n",
    "    \"ves_mc_gamma\": r\"$\\Gamma$ MC\",\n",
    "    \"ves_exp_0\": r\"Exp Constant\",\n",
    "    \"ves_exp_1\": r\"Exp Linear\",\n",
    "    \"ves_exp_2\": r\"Exp ReLu\",\n",
    "    \"ves_mc_exponential\": r\"Exp MC\",\n",
    "    \"ves_lr_0_0\": r\"$\\mathcal{N}$ L-C\",\n",
    "    \"ves_lr_0_1\": r\"$\\mathcal{N}$ L-L\",\n",
    "    \"ves_lr_0_2\": r\"$\\mathcal{N}$ L-R\",\n",
    "    \"ves_lr_2_0\": r\"$\\mathcal{N}$ R-C\",\n",
    "    \"ves_lr_2_1\": r\"$\\mathcal{N}$ R-L\",\n",
    "    \"ves_lr_2_2\": r\"$\\mathcal{N}$ R-R\",\n",
    "    \"ves_mc_gaussian\": r\"$\\mathcal{N}$ MC\",\n",
    "}\n",
    "\n",
    "\n",
    "def group_data(*, df:pd.DataFrame, col:Result_columns) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute means and average convergence curve for each\n",
    "     - kernel\n",
    "     - dimension\n",
    "     - length scale\n",
    "     - acquisition function\n",
    "     - y noise standard deviation\n",
    "\n",
    "    col may be one of:\n",
    "        \"y_max_diff\"\n",
    "        \"y_rec_diff_max\"\n",
    "        \"y_max_var\"\n",
    "        \"y_rec_var\"\n",
    "\n",
    "    This gives us a multi-index dataframe with unique nested keys\n",
    "    and mean, std, count regret for each row.\n",
    "    To index into a single kernel / dimension, we can use:\n",
    "\n",
    "        index = (kernel_type, len_scale, n_dim, y_noise_std, acq_func, steps)\n",
    "        df_grouped.loc[index] # returns mean, std, count\n",
    "\n",
    "    Args:\n",
    "        df: The dataframe to group and aggregate\n",
    "        col: The column to aggregate\n",
    "\n",
    "    Returns:\n",
    "        A dataframe with the mean, std, and count of the column\n",
    "        for each kernel/dim/len/af/y_std\n",
    "    \"\"\"\n",
    "    group_cols = [\n",
    "        \"kernel_type\",\n",
    "        \"len_scale\",\n",
    "        \"n_dim\",\n",
    "        \"y_noise_std\",\n",
    "        \"acq_func\",\n",
    "        \"steps\"\n",
    "    ]\n",
    "\n",
    "    df = df.copy()\n",
    "    df = df.explode([col, \"steps\"], ignore_index=True) # explode history into seperate rows\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"raise\")\n",
    "\n",
    "    df = df[group_cols + [col]]\n",
    "\n",
    "    df_grouped = df.groupby(group_cols)\n",
    "    df_grouped = df_grouped[col].agg(['mean', 'std', 'count'])\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "def plot_single(\n",
    "    *,\n",
    "    df:pd.DataFrame,\n",
    "    ax:plt.Axes,\n",
    "    acq_funs:list[str]=None,\n",
    "    err_scale:float=0.674, # +/- 50% confidence intervals\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot all the acquisition functions here on the same plot\n",
    "    \"\"\"\n",
    "    if acq_funs is None:\n",
    "        acq_funs = df.index.get_level_values('acq_func').unique()\n",
    "\n",
    "    for acq_func in acq_funs:\n",
    "        acq_data = df.loc[acq_func]\n",
    "        x = acq_data.index\n",
    "        y = acq_data[\"mean\"]\n",
    "        y_err = acq_data['std'] / np.sqrt(acq_data['count'])\n",
    "        ax.plot(x, y, label=ALG_NAMES[acq_func])\n",
    "        ax.fill_between(x, y - y_err * err_scale, y + y_err * err_scale, alpha=0.2)\n",
    "    ax.legend(framealpha=0.5, loc=\"lower left\")\n",
    "    ax.set_yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a38f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_everything_in_one_massive_figure(\n",
    "    *,\n",
    "    df_grouped: pd.DataFrame,\n",
    "    af_groups: list[list[str]]=None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Just plot everything available in the df_grouped. Ooptionally filter for\n",
    "    specific acq funs. \n",
    "\n",
    "    Args:\n",
    "        df_grouped: The dataframe with the results\n",
    "        af_groups: A list of lists of acq fun names to plot. If None, plot all acq funs.\n",
    "    \n",
    "    NOTE: this is mainly for quick results overview/exploration, not paper plots\n",
    "    \"\"\"\n",
    "    if af_groups is None:\n",
    "        af_groups = [df_grouped.index.get_level_values('acq_func').unique()]\n",
    "\n",
    "    kernels = df_grouped.index.get_level_values('kernel_type').unique()\n",
    "    y_std = df_grouped.index.get_level_values('y_noise_std').unique()\n",
    "    len_scales = df_grouped.index.get_level_values('len_scale').unique()\n",
    "    n_dims = df_grouped.index.get_level_values('n_dim').unique()\n",
    "    n_af_groups = len(af_groups)\n",
    "\n",
    "    num_plots = n_af_groups * len(kernels) * len(len_scales) * len(n_dims) * len(y_std)\n",
    "\n",
    "    fig, axes = plt.subplots(num_plots, 1, figsize=(10, num_plots*5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    # Super nested plot yeah!\n",
    "    for kernel_type in kernels:\n",
    "        for len_scale in len_scales:\n",
    "            for n_dim in n_dims:\n",
    "                for y_noise_std in y_std:\n",
    "\n",
    "                    title = f\"Kernel: {kernel_type}, Length Scale: {len_scale}, Dimension: {n_dim}, Y Noise Std: {y_noise_std:.1f}\"\n",
    "                    axes[k].set_title(title)\n",
    "\n",
    "                    df_acq_func = df_grouped.loc[(kernel_type, len_scale, n_dim, y_noise_std)]\n",
    "                    for af_group in af_groups:\n",
    "                        plot_single(df=df_acq_func, ax=axes[k], acq_funs=af_group)\n",
    "                        k += 1\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf34a56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reg_data.loc[('matern-5/2', 5, 2, 0.0)]\n",
    "df_grouped = group_data(df=df_master, col=\"y_rec_diff_mean\")\n",
    "fig = plot_everything_in_one_massive_figure(df_grouped=df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cols = [\n",
    "    \"y_max_diff\",\n",
    "    \"y_rec_diff_max\",\n",
    "    \"y_max_var\",\n",
    "    \"y_rec_var\"\n",
    "]\n",
    "\n",
    "af_groups = [\n",
    "    [\n",
    "        \"ves_gamma_0_0\",\n",
    "        \"ves_gamma_0_1\",\n",
    "        \"ves_gamma_0_2\",\n",
    "        \"ves_mc_gamma\",\n",
    "    ],\n",
    "    [\n",
    "        \"ves_exp_0\",\n",
    "        \"ves_exp_1\",\n",
    "        \"ves_exp_2\",\n",
    "        \"ves_mc_exponential\",\n",
    "    ],\n",
    "    [\n",
    "        \"ves_lr_0_0\",\n",
    "        \"ves_lr_0_1\",\n",
    "        \"ves_lr_0_2\",\n",
    "        \"ves_mc_gaussian\",\n",
    "    ],\n",
    "    [\n",
    "        \"ves_lr_2_0\",\n",
    "        \"ves_lr_2_1\",\n",
    "        \"ves_lr_2_2\",\n",
    "        \"ves_mc_gaussian\",\n",
    "    ],\n",
    "    [\n",
    "        \"random_search\",\n",
    "        \"expected_improvement\",\n",
    "        \"ves_lr_2_2\",\n",
    "        \"ves_lr_0_2\",\n",
    "        \"ves_mc_gaussian\",\n",
    "        \"ves_mc_exponential\",\n",
    "        \"ves_mc_gamma\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "kernel_type = \"matern-5/2\"\n",
    "len_scale = 5\n",
    "n_dim = 2\n",
    "y_noise_std = 0.0\n",
    "\n",
    "y_noise_std_levels = df_master[\"y_noise_std\"].unique()\n",
    "\n",
    "index_det = (kernel_type, len_scale, n_dim, min(y_noise_std_levels))\n",
    "index_noisy = (kernel_type, len_scale, n_dim, max(y_noise_std_levels))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 4.5), sharex=True)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Regret\")\n",
    "axes[1, 0].set_ylabel(\"Expected Regret\")\n",
    "\n",
    "for i in range(3):\n",
    "    axes[1, i].set_xlabel(\"Steps\")\n",
    "    axes[0, i].set_ylim(0.09, 1.9)\n",
    "    axes[1, i].set_ylim(0.15, 1.9)\n",
    "\n",
    "\n",
    "axes[1, 1].set_yticklabels([])\n",
    "axes[1, 2].set_yticklabels([])\n",
    "axes[0, 1].set_yticklabels([])\n",
    "axes[0, 2].set_yticklabels([])\n",
    "\n",
    "\n",
    "# first 2 plots is just EXP and Gamma variants\n",
    "df_i = group_data(df=df_master, col=\"y_max_diff\").loc[index_det]\n",
    "plot_single(df=df_i, ax=axes[0, 0], acq_funs=af_groups[1])\n",
    "plot_single(df=df_i, ax=axes[0, 1], acq_funs=af_groups[0])\n",
    "\n",
    "\n",
    "# next two plots are LR variants on noisy\n",
    "df_i = group_data(df=df_master, col=\"y_rec_diff_mean\").loc[index_noisy]\n",
    "plot_single(df=df_i, ax=axes[1, 0], acq_funs=af_groups[2])\n",
    "plot_single(df=df_i, ax=axes[1, 1], acq_funs=af_groups[3])\n",
    "\n",
    "\n",
    "# final two plots: noise free and noisy for VES algos + EI + RS\n",
    "df_i = group_data(df=df_master, col=\"y_max_diff\").loc[index_det]\n",
    "plot_single(df=df_i, ax=axes[0, 2], acq_funs=af_groups[4])\n",
    "\n",
    "df_i = group_data(df=df_master, col=\"y_rec_diff_mean\").loc[index_noisy]\n",
    "plot_single(df=df_i, ax=axes[1, 2], acq_funs=af_groups[4])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(SAVE_DIR / \"paper_results.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da32b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721bbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c85ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
